{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a486860d",
   "metadata": {},
   "source": [
    "# Final Analysis with EPO data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325fb00",
   "metadata": {},
   "source": [
    "Here I attempt to perform a cohesive analysis of the data. All file imports are specified in the associated `read_me` document. It is noted that importing the data can take a significant amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079da33",
   "metadata": {},
   "source": [
    "##### Adjusting the notebook cells to allow for a wider fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b73bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting screen \n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a73100",
   "metadata": {},
   "source": [
    "#### Relevant imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423bc581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from itertools import count\n",
    "import geopandas as gpd\n",
    "import pydot\n",
    "from networkx.drawing.nx_pydot import to_pydot\n",
    "import igraph as ig\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "from textwrap import wrap\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Helvetica Neue\" # Adjusting all of the plot fonts for legibility\n",
    "\n",
    "%matplotlib inline # Ensuring the plots are outputted correctly in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836a41af",
   "metadata": {},
   "source": [
    "Initialising a function for a rapid description of selected IPC descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPC_descriptions = pd.read_csv('/Users/joebacchus/Desktop/CASA/All_IPC.txt',sep='\t').astype(str) # --> IPC_DESCRIPTIONS.txt\n",
    "def translate_ipc(IPC):\n",
    "    '''\n",
    "    Returns the description of an inputted IPC code, to any scale of character length.\n",
    "    '''\n",
    "    return list(IPC_descriptions.loc[IPC_descriptions['IPC'] == IPC]['Description']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0189c1",
   "metadata": {},
   "source": [
    "# Importing the RAW EPO patent and citation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a688a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patents_raw_EPO = pd.read_csv('/Users/joebacchus/Desktop/CASA/Data Original/Patent data/202001_EPO_Inventor_reg.txt', sep='|')  # --> EPO_PATENTS_RAW.txt\n",
    "IPCs_raw_EPO = pd.read_csv('/Users/joebacchus/Desktop/CASA/Data Original/Patent data/202001_EPO_IPC.txt', sep='|')              # --> EPO_IPC_RAW.txt\n",
    "Citations_raw_EPO = pd.read_csv('/Users/joebacchus/Desktop/CASA/Data Original/Citation data/202001_EPO_CITATIONS.txt', sep='|') # --> EPO_CITATIONS_RAW.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0f1a6",
   "metadata": {},
   "source": [
    "<font color='blue'>The IPC precision value n is to be modified here and all subsequent cells are to be rerun to investigate the effects with this level.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a74aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1 # Adjust according to anaylsis\n",
    "IPCs_raw_EPO['IPC'] = IPCs_raw_EPO['IPC'].astype(str).str[:n] # Shortening the IPC codes to n-characters of precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4174c4",
   "metadata": {},
   "source": [
    "Restricting the patents to the UK. Note that we perform this via the regional code as supposed to the country code to avoid missing patents labelled as part of the 'UK' as supposed to 'GB'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65822199",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patents_raw_EPO_PRE = Patents_raw_EPO.loc[Patents_raw_EPO['reg_code'].str.contains('^UK')][['app_nbr','appln_id','reg_code']] # Eleminating unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPCs_raw_EPO = IPCs_raw_EPO[['appln_id','prio_year','IPC']] # Eleminating unnecessary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc14ee0",
   "metadata": {},
   "source": [
    "Here we associate each patent to the list of it's corresponding IPC codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40330f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPO_PAT_IPC = Patents_raw_EPO_PRE.merge(IPCs_raw_EPO, left_on = 'appln_id', right_on = 'appln_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f02453",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPO_PAT_IPC = EPO_PAT_IPC[['app_nbr','reg_code','prio_year','IPC']].drop_duplicates() # Eleminating unnecessary columns and possible duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b493dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patents_EPO = EPO_PAT_IPC.rename(columns={'app_nbr':'Application','reg_code':'Region','prio_year':'Patent Year','IPC':'IPC'}) # Renaming columns for legibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c290811",
   "metadata": {},
   "outputs": [],
   "source": [
    "Citations_raw_EPO = Citations_raw_EPO[['Citing_app_nbr','Cited_App_nbr','Citing_pub_date']] # Eleminating unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee49aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Citations_raw_EPO['Citing_pub_date'] = Citations_raw_EPO['Citing_pub_date'].astype(str).str[:4]   # Modifying the citation dates to only list the year (As supposed to a specific date)\n",
    "Citations_raw_EPO = Citations_raw_EPO.fillna(False).astype(str)                                   # Modifying the data-type and accounting for missing values.\n",
    "Citations_raw_EPO = Citations_raw_EPO.loc[Citations_raw_EPO['Cited_App_nbr'].str.contains('^EP')] # Restricting the cited applications to EPO patents (As a preliminary reduction of the file size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3edf75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Citations_raw_EPO = Citations_raw_EPO.drop_duplicates() # Dropping possible duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = Patents_EPO.merge(Citations_raw_EPO, left_on = 'Application', right_on = 'Citing_app_nbr') # Ensuring that all citing patents are complete with their detailed characteristics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d238fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = part1.drop(columns=['Application']) # Removing the now duplicated columns (As this is now simply the Source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = part1.rename(columns={'Citing_app_nbr':'Source','Cited_App_nbr':'Target','Citing_pub_date':'Citation Year','IPC':'Source IPC','Region':'Source Region', 'Patent Year':'Source Patent Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf65e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = part1.merge(Patents_EPO, left_on = 'Target', right_on = 'Application') # Ensuring that all cited patents are complete with their detailed characteristics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = part2.drop(columns=['Application']) # Removing the now duplicated columns (As this is now simply the Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = part2.rename(columns = {'Region':'Target Region', 'Patent Year':'Target Patent Year', 'IPC': 'Target IPC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd5423",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = part2[['Source','Target','Citation Year','Source IPC', 'Source Region', 'Source Patent Year', 'Target IPC', 'Target Region','Target Patent Year']] # Re-ordering columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c8154",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_EPO = part2.drop_duplicates() # Finalising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b785b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminates an error occuring in an IPC precision of n=1 \n",
    "Data = Data_EPO.dropna()\n",
    "Data = Data.drop(Data[Data['Source IPC'] == 'n'].index)\n",
    "Data = Data.drop(Data[Data['Target IPC'] == 'n'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236ae1d",
   "metadata": {},
   "source": [
    "We hence conduct the rest of our anaylsis with only a single comprehensive table: `Data`. On occasion we may also take advantage of the more simplified structure of `Patents`. For this reason they are shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7970c608",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06469db",
   "metadata": {},
   "source": [
    "### Patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f766815",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658deb1",
   "metadata": {},
   "source": [
    "We now prepare some useful lists and dictionaries to gain some preliminary insights into the prepared data and allow more concise manipulations hereafter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d1e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Present_IPCs = sorted(list(set(list(np.array(Data[['Source IPC','Target IPC']]).flatten()))))                      # List of all possible IPC classes\n",
    "Present_Dates_Pat = sorted(list(set(list(np.array(Data[['Source Patent Year','Target Patent Year']]).flatten())))) # List of all possible Patent creation years\n",
    "Present_Dates_Cit = sorted(list(set(list(np.array(Data[['Citation Year']]).flatten()))))                           # List of all possible Patent citation years\n",
    "Present_Regions = sorted(list(set(list(np.array(Data[['Source Region','Target Region']]).flatten()))))             # List of all possible regions\n",
    "\n",
    "Present_IPCs_Keys = dict(list(zip(Present_IPCs,np.arange(len(Present_IPCs)))))                                     # IPCs associated in alphabetical order with a number (Facilitates future manipulations)\n",
    "\n",
    "print('Number of IPCs:',len(Present_IPCs),'|','Number of Dates (Patents):',len(Present_Dates_Pat),'|','Number of Dates (Citations):',len(Present_Dates_Cit),'|','Number of Regions:',len(Present_Regions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72179b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patents_dates = list(zip(list(list(Data['Source'])+list(Data['Target'])),list(list(Data['Source Patent Year'])+list(Data['Target Patent Year']))))\n",
    "Patents_dates = pd.DataFrame(Patents_dates, columns = [['Patent','Date']])\n",
    "Patents_dates['IPC'] = list(Data['Source IPC'])+list(Data['Target IPC'])\n",
    "Patents_dates = Patents_dates.drop_duplicates().astype(str)\n",
    "Patents_dates.to_clipboard()\n",
    "Patents_dates = pd.read_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d4b9c",
   "metadata": {},
   "source": [
    "### Number of patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f5180d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Storing_array = np.zeros((len(Present_IPCs_Keys),len(Present_Dates_Pat))) # Initialising empty storing array\n",
    "\n",
    "for i in range(len(Present_Dates_Pat)):\n",
    "    \n",
    "    # Creating IPC Citation relationships\n",
    "    Data_select = Patents_dates.loc[Patents_dates['Date'] == int(Present_Dates_Pat[i])] # Selecting all patents created in specific year\n",
    "    Counts_prelim = dict(Data_select['IPC'].value_counts()) # Converting multiple citation counts into weights\n",
    "    extract_information = list(zip(list(Counts_prelim.keys()),list(Counts_prelim.values())))\n",
    "\n",
    "    # Storing all values into the storing array\n",
    "    for j in range(len(extract_information)):\n",
    "        Storing_array[Present_IPCs_Keys[extract_information[j][0]]][i] = extract_information[j][1]\n",
    "        \n",
    "plt.figure(figsize=(20, 10))\n",
    "Dates_plotting = np.arange(min(np.array(Present_Dates_Pat).astype(int)), max(np.array(Present_Dates_Pat).astype(int)) + 1) # Dates for plotting\n",
    "Colors = pl.cm.coolwarm(np.linspace(0, 1, len(Present_IPCs))) # Colors for plotting\n",
    "\n",
    "Most_Cited = []\n",
    "for i in range(len(Present_Dates_Pat)):\n",
    "    Most_Cited.append(list(Present_IPCs_Keys.keys())[np.argmax(Storing_array.T[i])])\n",
    "\n",
    "for k in range(len(Present_IPCs_Keys)):\n",
    "    plt.plot(Dates_plotting, Storing_array[k], color=Colors[k], label=f'{list(Present_IPCs_Keys.keys())[k]} : {translate_ipc(list(Present_IPCs_Keys.keys())[k])[0]}')\n",
    "\n",
    "for k in range(len(Dates_plotting)):\n",
    "    plt.axvline(x=Dates_plotting[k], color='black', linestyle=':', linewidth=0.5)\n",
    "    highest_point = max(Storing_array[:, k])  # Get the highest point for this instance\n",
    "    plt.text(Dates_plotting[k] - 0.19, highest_point + -3.8, Most_Cited[k], fontsize=12, zorder=20, color='White')  # Adjust the y coordinate to move the text above the highest point and set zorder to 10\n",
    "    plt.scatter(Dates_plotting[k], highest_point, color=Colors[Present_IPCs_Keys[Most_Cited[k]]], s=200, zorder=10)  # Add a point at the highest point and set zorder to 10\n",
    "\n",
    "leg = plt.legend(loc='upper right', borderaxespad=0.1, fancybox=True, facecolor='white', frameon=True, framealpha=1, edgecolor='white', fontsize=12) \n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(10) \n",
    "\n",
    "#plt.xlabel('Year', fontsize=15)\n",
    "plt.ylabel('Number of patents approved for designated year', fontsize=15)\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'PLOT1' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb55a0",
   "metadata": {},
   "source": [
    "### Number of patents (Normalised stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822b9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Storing_array = np.zeros((len(Present_IPCs_Keys),len(Present_Dates_Pat))) # Initialising empty storing array\n",
    "\n",
    "for i in range(len(Present_Dates_Pat)):\n",
    "    \n",
    "    # Creating IPC Citation relationships\n",
    "    Data_select = Patents_dates.loc[Patents_dates['Date'] == int(Present_Dates_Pat[i])] # Selecting all patents created in specific year\n",
    "    Counts_prelim = dict(Data_select['IPC'].value_counts()) # Converting multiple citation counts into weights\n",
    "    extract_information = list(zip(list(Counts_prelim.keys()),list(Counts_prelim.values())))\n",
    "\n",
    "    # Storing all values into the storing array\n",
    "    for j in range(len(extract_information)):\n",
    "        Storing_array[Present_IPCs_Keys[extract_information[j][0]]][i] = extract_information[j][1]\n",
    "\n",
    "for i in range(len(Storing_array.T)):\n",
    "    if np.sum(Storing_array.T[i]) != 0:\n",
    "        Storing_array.T[i] = Storing_array.T[i]/(np.sum(Storing_array.T[i]))\n",
    "        \n",
    "plt.figure(figsize=(20, 5))\n",
    "Dates_plotting = np.arange(min(np.array(Present_Dates_Pat).astype(int)), max(np.array(Present_Dates_Pat).astype(int)) + 1) # Dates for plotting\n",
    "Colors = pl.cm.coolwarm(np.linspace(0, 1, len(Present_IPCs))) # Colors for plotting\n",
    "\n",
    "Most_Cited = []\n",
    "for i in range(len(Present_Dates_Pat)):\n",
    "    Most_Cited.append(list(Present_IPCs_Keys.keys())[np.argmax(Storing_array.T[i])])\n",
    "\n",
    "plt.stackplot(Dates_plotting,Storing_array,labels=Present_IPCs_Keys.keys(),colors = Colors)\n",
    "\n",
    "for k in range(len(Dates_plotting)):\n",
    "    plt.axvline(x=Dates_plotting[k], color='black', linestyle=':', linewidth=0.5)\n",
    "    #highest_point = 2  # Get the highest point for this instance\n",
    "    #plt.text(Dates_plotting[k], 1+0.01, Most_Cited[k], fontsize=12, zorder=20, color='Black')  # Adjust the y coordinate to move the text above the highest point and set zorder to 10\n",
    "    #plt.scatter(Dates_plotting[k], highest_point, color=Colors[Present_IPCs_Keys[Most_Cited[k]]], s=200, zorder=10)  # Add a point at the highest point and set zorder to 10\n",
    "\n",
    "#plt.legend(loc='upper right', borderaxespad=0.1, fancybox=True, facecolor='white', frameon=True, framealpha=1, edgecolor='white') \n",
    "#plt.xlabel('Year', fontsize=15)\n",
    "plt.ylabel('Share', fontsize=15)\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x * 100) for x in plt.gca().get_yticks()])\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'PLOT2' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=False)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "Storing_array_PAT = Storing_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb89b8ba",
   "metadata": {},
   "source": [
    "# Number of patents correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_pd = pd.DataFrame(Storing_array.T,columns=Present_IPCs)\n",
    "matrix_corr = matrix_pd.corr()\n",
    "matrix_plot = np.array(matrix_corr)\n",
    "labels = list(matrix_corr)\n",
    "\n",
    "plt.figure(figsize=(10, 10),dpi=100)\n",
    "plt.imshow(matrix_plot, cmap='coolwarm', vmin=-1, vmax=1, aspect='auto')\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        plt.text(j, i, f'{matrix_plot[i, j]:.2f}', ha='center', va='center', fontsize=14, color='black')\n",
    "\n",
    "plt.xticks(np.arange(len(labels)), labels, fontsize=14)\n",
    "plt.yticks(np.arange(len(labels)), labels, fontsize=14)\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'PLOT3' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=False)\n",
    "\n",
    "#plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4bf35",
   "metadata": {},
   "source": [
    "### Number of citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b908d063",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Storing_array = np.zeros((len(Present_IPCs_Keys),len(Present_Dates_Cit))) # Initialising empty storing array\n",
    "\n",
    "for i in range(len(Present_Dates_Cit)):\n",
    "    \n",
    "    # Creating IPC Citation relationships\n",
    "    Data_select = Data.loc[Data['Citation Year'] == Present_Dates_Cit[i]] # Selecting all patents created in specific year\n",
    "    Counts_prelim = dict(Data_select[['Source IPC','Target IPC']].value_counts()) # Converting multiple citation counts into weights\n",
    "    Counts = [(key[0], key[1], value) for key, value in Counts_prelim.items()] # Formatted correctly\n",
    "    \n",
    "    # Creating graph\n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_weighted_edges_from(Counts)\n",
    "    graph.remove_edges_from(nx.selfloop_edges(graph)) # NOT ACCOUNTING FOR SELF CITATIONS\n",
    "    extract_information = list(graph.in_degree(weight='weight')) # Accounting for the counts\n",
    "    \n",
    "    # Storing all values into the storing array\n",
    "    for j in range(len(extract_information)):\n",
    "        Storing_array[Present_IPCs_Keys[extract_information[j][0]]][i] = extract_information[j][1]\n",
    "        \n",
    "plt.figure(figsize=(20, 10))\n",
    "Dates_plotting = np.arange(min(np.array(Present_Dates_Cit).astype(int)), max(np.array(Present_Dates_Cit).astype(int)) + 1) # Dates for plotting\n",
    "Colors = pl.cm.coolwarm(np.linspace(0, 1, len(Present_IPCs))) # Colors for plotting\n",
    "\n",
    "Most_Cited = []\n",
    "for i in range(len(Present_Dates_Cit)):\n",
    "    Most_Cited.append(list(Present_IPCs_Keys.keys())[np.argmax(Storing_array.T[i])])\n",
    "\n",
    "for k in range(len(Present_IPCs_Keys)):\n",
    "    plt.plot(Dates_plotting, Storing_array[k], color=Colors[k], label=f'{list(Present_IPCs_Keys.keys())[k]} : {translate_ipc(list(Present_IPCs_Keys.keys())[k])[0]}')\n",
    "\n",
    "for k in range(len(Dates_plotting)):\n",
    "    plt.axvline(x=Dates_plotting[k], color='black', linestyle=':', linewidth=0.5)\n",
    "    highest_point = max(Storing_array[:, k])  # Get the highest point for this instance\n",
    "    plt.text(Dates_plotting[k] - 0.19, highest_point + -8, Most_Cited[k], fontsize=12, zorder=20, color='White')  # Adjust the y coordinate to move the text above the highest point and set zorder to 10\n",
    "    plt.scatter(Dates_plotting[k], highest_point, color=Colors[Present_IPCs_Keys[Most_Cited[k]]], s=200, zorder=10)  # Add a point at the highest point and set zorder to 10\n",
    "\n",
    "leg = plt.legend(loc='upper right', borderaxespad=0.1, fancybox=True, facecolor='white', frameon=True, framealpha=1, edgecolor='white', fontsize=12) \n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(10) \n",
    "\n",
    "plt.ylabel('Number of citations occurring for designated year', fontsize=15)\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'PLOT4' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b1f794",
   "metadata": {},
   "source": [
    "### Number of citations (Normalised stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e627e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "Storing_array = np.zeros((len(Present_IPCs_Keys),len(Present_Dates_Cit))) # Initialising empty storing array\n",
    "\n",
    "for i in range(len(Present_Dates_Cit)):\n",
    "    \n",
    "    # Creating IPC Citation relationships\n",
    "    Data_select = Data.loc[Data['Citation Year'] == Present_Dates_Cit[i]] # Selecting all patents created in specific year\n",
    "    Counts_prelim = dict(Data_select[['Source IPC','Target IPC']].value_counts()) # Converting multiple citation counts into weights\n",
    "    Counts = [(key[0], key[1], value) for key, value in Counts_prelim.items()] # Formatted correctly\n",
    "    \n",
    "    # Creating graph\n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_weighted_edges_from(Counts)\n",
    "    graph.remove_edges_from(nx.selfloop_edges(graph)) # NOT ACCOUNTING FOR SELF CITATIONS\n",
    "    extract_information = list(graph.in_degree(weight='weight')) # Accounting for the counts\n",
    "    \n",
    "    # Storing all values into the storing array\n",
    "    for j in range(len(extract_information)):\n",
    "        Storing_array[Present_IPCs_Keys[extract_information[j][0]]][i] = extract_information[j][1]\n",
    "\n",
    "for i in range(len(Storing_array.T)):\n",
    "    if np.sum(Storing_array.T[i]) != 0:\n",
    "        Storing_array.T[i] = Storing_array.T[i]/(np.sum(Storing_array.T[i]))\n",
    "        \n",
    "plt.figure(figsize=(20, 5))\n",
    "Dates_plotting = np.arange(min(np.array(Present_Dates_Cit).astype(int)), max(np.array(Present_Dates_Cit).astype(int)) + 1) # Dates for plotting\n",
    "Colors = pl.cm.coolwarm(np.linspace(0, 1, len(Present_IPCs))) # Colors for plotting\n",
    "\n",
    "Most_Cited = []\n",
    "for i in range(len(Present_Dates_Cit)):\n",
    "    Most_Cited.append(list(Present_IPCs_Keys.keys())[np.argmax(Storing_array.T[i])])\n",
    "\n",
    "plt.stackplot(Dates_plotting,Storing_array,labels=Present_IPCs_Keys.keys(),colors = Colors)\n",
    "\n",
    "for k in range(len(Dates_plotting)):\n",
    "    plt.axvline(x=Dates_plotting[k], color='black', linestyle=':', linewidth=0.5)\n",
    "    #highest_point = 2  # Get the highest point for this instance\n",
    "    #plt.text(Dates_plotting[k], 1+0.01, Most_Cited[k], fontsize=12, zorder=20, color='Black')  # Adjust the y coordinate to move the text above the highest point and set zorder to 10\n",
    "    #plt.scatter(Dates_plotting[k], highest_point, color=Colors[Present_IPCs_Keys[Most_Cited[k]]], s=200, zorder=10)  # Add a point at the highest point and set zorder to 10\n",
    "\n",
    "#plt.legend(loc='upper right', borderaxespad=0.1, fancybox=True, facecolor='white', frameon=True, framealpha=1, edgecolor='white') \n",
    "#plt.xlabel('Year', fontsize=15)\n",
    "plt.ylabel('Share', fontsize=15)\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x * 100) for x in plt.gca().get_yticks()])\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'PLOT5' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=False)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "Storing_array_CIT = Storing_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c949f69",
   "metadata": {},
   "source": [
    "# Number of citations correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_pd = pd.DataFrame(Storing_array.T,columns=Present_IPCs)\n",
    "matrix_corr = matrix_pd.corr()\n",
    "matrix_plot = np.array(matrix_corr)\n",
    "labels = list(matrix_corr)\n",
    "\n",
    "plt.figure(figsize=(10, 10),dpi=100)\n",
    "plt.imshow(matrix_plot, cmap='coolwarm', vmin=-1, vmax=1, aspect='auto')\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        plt.text(j, i, f'{matrix_plot[i, j]:.2f}', ha='center', va='center', fontsize=14, color='black')\n",
    "\n",
    "plt.xticks(np.arange(len(labels)), labels, fontsize=14)\n",
    "plt.yticks(np.arange(len(labels)), labels, fontsize=14)\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'PLOT6' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=False)\n",
    "\n",
    "#plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b526798",
   "metadata": {},
   "source": [
    "# Cross-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e963cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_pd_PAT = pd.DataFrame(Storing_array_PAT.T,columns=Present_IPCs)\n",
    "matrix_pd_CIT = pd.DataFrame(Storing_array_CIT.T,columns=Present_IPCs)\n",
    "labels = Present_IPCs\n",
    "\n",
    "matrix_PC = np.zeros((len(Present_IPCs),len(Present_IPCs)))\n",
    "for j in range(len(Present_IPCs)):\n",
    "    for i in range(len(Present_IPCs)):\n",
    "        matrix_PC[j][i] = matrix_pd_PAT[Present_IPCs[j]].corr(matrix_pd_CIT[Present_IPCs[i]])\n",
    "\n",
    "plt.figure(figsize=(10, 10),dpi=100)\n",
    "plt.imshow(matrix_PC, cmap='coolwarm', vmin=-1, vmax=1, aspect='auto')\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    for j in range(len(labels)):\n",
    "        plt.text(j, i, f'{matrix_PC[i, j]:.2f}', ha='center', va='center', fontsize=14, color='black')\n",
    "\n",
    "plt.xlabel('Citation count', fontsize=14)\n",
    "plt.ylabel('Patent count', fontsize=14)\n",
    "plt.xticks(np.arange(len(labels)), labels, fontsize=14)\n",
    "plt.yticks(np.arange(len(labels)), labels, fontsize=14)\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'PLOT7' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=False)\n",
    "\n",
    "#plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b291517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ig.Graph(directed=True)\n",
    "graph.add_vertices(Present_IPCs)\n",
    "graph.Weighted_Adjacency(matrix_PC+1)\n",
    "graph.es['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.get_cmap('coolwarm')  # Choose any colormap you like\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ig.plot(\n",
    "    graph,\n",
    "    layout=graph.layout(layout='reingold_tilford_circular'),\n",
    "    target=ax,\n",
    "    vertex_size=[s * 0.015 + 0.005 for s in in_degrees],\n",
    "    mark_groups=True,\n",
    "    vertex_frame_width=1.0,\n",
    "    vertex_frame_color='White',\n",
    "    vertex_label=graph.vs[\"name\"],\n",
    "    vlabel_size=10.0,\n",
    "    vertex_color=[colormap(d/max_in_degrees) for d in in_degrees],\n",
    "    edge_width=[w*0.01 + 0.05 for w in graph.es['weight']],\n",
    "    vertex_label_color='White',\n",
    "    edge_color=[colormap(w/max(graph.es['weight'])) for w in graph.es['weight']],\n",
    "    edge_arrow_size=[w*0.00001 + 0.001 for w in graph.es['weight']]\n",
    ")\n",
    "\n",
    "fig.set_size_inches(20, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bdc020",
   "metadata": {},
   "source": [
    "# Characteristics (UNUSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_CHA = Data[['Source','Target','Source Patent Year','Target Patent Year']].drop_duplicates().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500d509",
   "metadata": {},
   "outputs": [],
   "source": [
    "av_clust = []\n",
    "av_clust_ind = []\n",
    "edges_source = []\n",
    "edges_target = []\n",
    "\n",
    "for i in range(len(Present_Dates_Pat)):\n",
    "    Data_CHA_u = Data_CHA.loc[Data_CHA['Source Patent Year'] == Present_Dates_Pat[i]]\n",
    "    \n",
    "    edges_source_ind = list(Data_CHA_u['Source'])\n",
    "    edges_target_ind = list(Data_CHA_u['Target'])\n",
    "    edges_source_ind = [item for sublist in edges_source_ind for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "    edges_target_ind = [item for sublist in edges_target_ind for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "    edges_ind = list(zip(list(edges_source_ind),list(edges_target_ind)))\n",
    "\n",
    "    # Creating graph\n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_edges_from(edges_ind)\n",
    "    av_clust_ind.append(nx.average_clustering(graph))\n",
    "    \n",
    "    edges_source.append(edges_source_ind)\n",
    "    edges_target.append(edges_target_ind)\n",
    "    edges_source = [item for sublist in edges_source for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "    edges_target = [item for sublist in edges_target for item in (sublist if isinstance(sublist, list) else [sublist])]\n",
    "    edges = list(zip(list(edges_source),list(edges_target)))\n",
    "    \n",
    "    # Creating graph\n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_edges_from(edges)\n",
    "    av_clust.append(nx.average_clustering(graph))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b3cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "Dates_plotting = np.arange(min(np.array(Present_Dates_Pat).astype(int)), max(np.array(Present_Dates_Pat).astype(int)) + 1) # Dates for plotting\n",
    "plt.plot(Dates_plotting, av_clust, color='black', label='Cumulative')\n",
    "plt.plot(Dates_plotting, av_clust_ind, color='grey', label='Independent')\n",
    "\n",
    "for k in range(len(Dates_plotting)):\n",
    "    plt.axvline(x=Dates_plotting[k], color='black', linestyle=':', linewidth=0.5)\n",
    "    \n",
    "leg = plt.legend(loc='upper right', borderaxespad=0.1, fancybox=True, facecolor='white', frameon=True, framealpha=1, edgecolor='white', fontsize=12) \n",
    "for line in leg.get_lines():\n",
    "    line.set_linewidth(10) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d9cee",
   "metadata": {},
   "source": [
    "# Specific (UNUSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524f82fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Storing_array = np.zeros((len(Present_IPCs_Keys),len(Present_Dates_Cit))) # Initialising empty storing array\n",
    "IPC_Selected = Present_IPCs[0] # Select the IPC\n",
    "\n",
    "for i in range(len(Present_Dates_Cit)):\n",
    "    \n",
    "    # Creating IPC Citation relationships\n",
    "    Data_select = Data.loc[Data['Citation Year'] == Present_Dates_Cit[i]] # Selecting all patents created in specific year\n",
    "    Data_select = Data_select.loc[Data_select['Source IPC'] == IPC_Selected] # Now choose IPC class of interest\n",
    "    Counts_prelim = dict(Data_select[['Source IPC','Target IPC']].value_counts()) # Converting multiple citation counts into weights\n",
    "    Counts = [(key[0], key[1], value) for key, value in Counts_prelim.items()] # Formatted correctly\n",
    "    \n",
    "    # Creating graph\n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_weighted_edges_from(Counts)\n",
    "    extract_information = list(graph.in_degree(weight='weight')) # Accounting for the counts\n",
    "    \n",
    "    # Storing all values into the storing array\n",
    "    for j in range(len(extract_information)):\n",
    "        Storing_array[Present_IPCs_Keys[extract_information[j][0]]][i] = extract_information[j][1]\n",
    "        \n",
    "plt.figure(figsize=(20,10),facecolor='lightgrey')\n",
    "Dates_plotting = np.arange(min(np.array(Present_Dates_Cit).astype(int)),max(np.array(Present_Dates_Cit).astype(int))+1) # Dates for plotting\n",
    "Colors = pl.cm.cividis(np.linspace(0,1,len(Present_IPCs))) # Colors for plotting\n",
    "\n",
    "Most_Cited = []\n",
    "for i in range(len(Present_Dates_Cit)):\n",
    "    Most_Cited.append(list(Present_IPCs_Keys.keys())[np.argmax(Storing_array.T[i])])\n",
    "    \n",
    "for k in range(len(Present_IPCs_Keys)):\n",
    "    if list(Present_IPCs_Keys.keys())[k] != IPC_Selected:\n",
    "        plt.plot(Dates_plotting, Storing_array[k], color=Colors[k], label=list(Present_IPCs_Keys.keys())[k])\n",
    "    else:\n",
    "        plt.plot(Dates_plotting, Storing_array[k], color='Blue', linestyle=':', label=list(Present_IPCs_Keys.keys())[k])\n",
    "\n",
    "for k in range(len(Dates_plotting)):\n",
    "    plt.axvline(x=Dates_plotting[k], color=Colors[Present_IPCs_Keys[Most_Cited[k]]], linewidth=0.5)\n",
    "    plt.text(Dates_plotting[k]-0.2, max(Storing_array.flatten())+max(Storing_array.flatten())/100, Most_Cited[k], fontsize=10)\n",
    "    \n",
    "plt.legend(frameon=False,loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=2)\n",
    "plt.title(f'Most prevalent citation classifications per year for class {IPC_Selected}')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of citations from specific year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f000fd",
   "metadata": {},
   "source": [
    "# Mapping IPC presence (UNUSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15edcb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapefile = gpd.read_file(\"/Users/joebacchus/Desktop/CASA/NUTS Shapefiles/NUTS_RG_20M_2021_3035.shp\")\n",
    "shapefile_UK = shapefile.loc[shapefile['CNTR_CODE'] == \"UK\"] # Can modify UK\n",
    "shapefile_UK = shapefile_UK.loc[shapefile_UK['LEVL_CODE'] == 3][['NUTS_ID','geometry']].rename(columns={'NUTS_ID':'Region','geometry':'geometry'}) # Restricting to selected NUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589c548",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regions_shapefile = list(shapefile_UK['Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPC_Selected = 'B01' # Select the IPC\n",
    "Storing_array = []\n",
    "\n",
    "for i in range(len(Regions_shapefile)):\n",
    "    IPC_count_region = dict(Patents.loc[Patents['Region'] == Regions_shapefile[i]]['IPC'].value_counts())\n",
    "    IPC_count_region = pd.DataFrame(list(zip(list(IPC_count_region.keys()),list(IPC_count_region.values()))),columns=[['IPC','Count']])\n",
    "    store_value = np.array(IPC_count_region.loc[(IPC_count_region['IPC'] == IPC_Selected).values]['Count']).flatten()\n",
    "    Storing_array.append(store_value) # Add count of particular IPC to array\n",
    "    \n",
    "Storing_array = [-1000 if x.size == 0 else x.item() for x in Storing_array]\n",
    "shapefile_UK['Values'] = Storing_array # Assigning to the values\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "cmap = 'Spectral_r'\n",
    "norm = plt.Normalize(-shapefile_UK['Values'].max(), shapefile_UK['Values'].max())\n",
    "shapefile_UK.plot(ax=ax, column='Values', cmap=cmap, linewidth=0.1, edgecolor='black', norm=norm)\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "#cbar = plt.colorbar(sm, ax=ax, fraction=0.02, pad=0.02)\n",
    "cbar.set_label('Values')\n",
    "\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75cb5a6",
   "metadata": {},
   "source": [
    "# Graphing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcccb5c",
   "metadata": {},
   "source": [
    "### Citations unnormalised total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ig.Graph(directed=True)\n",
    "graph.add_vertices(Present_IPCs)\n",
    "graph.add_edges(list(dict(Data[['Source IPC','Target IPC']].value_counts()).keys()))\n",
    "graph.simplify() # Remove self loops\n",
    "to_delete_ids = [v.index for v in graph.vs if v.degree() == 0] # Delete isolated nodes\n",
    "graph.delete_vertices(to_delete_ids)\n",
    "graph.delete_vertices('na')\n",
    "\n",
    "# Adding weights\n",
    "Counts_prelim = dict(Data[['Source IPC','Target IPC']].value_counts())\n",
    "graph.es['weight'] = list(Counts_prelim.values())\n",
    "\n",
    "communities = graph.community_edge_betweenness(weights=graph.es['weight'])\n",
    "communities = communities.as_clustering()\n",
    "bridges = graph.bridges()\n",
    "\n",
    "in_degrees = graph.degree(mode='in')\n",
    "max_in_degrees = max(in_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36993ada",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a colormap for node colors\n",
    "colormap = plt.cm.get_cmap('coolwarm')  # Choose any colormap you like\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ig.plot(\n",
    "    graph,\n",
    "    layout=graph.layout(layout='reingold_tilford_circular'),\n",
    "    target=ax,\n",
    "    vertex_size=[s * 0.003 + 0.02 for s in in_degrees],\n",
    "    mark_groups=True,\n",
    "    vertex_frame_width=1.0,\n",
    "    vertex_frame_color='White',\n",
    "    #vertex_label=graph.vs[\"name\"],\n",
    "    vlabel_size=10.0,\n",
    "    vertex_color=[colormap(d/max_in_degrees) for d in in_degrees],\n",
    "    edge_width=[w*0.001 + 0.05 for w in graph.es['weight']],\n",
    "    vertex_label_color='White',\n",
    "    edge_color=[colormap(w/max(graph.es['weight'])) for w in graph.es['weight']],\n",
    "    edge_arrow_size=[w*0.0000005 + 0.001 for w in graph.es['weight']]\n",
    ")\n",
    "\n",
    "layout = graph.layout(layout='reingold_tilford_circular')\n",
    "\n",
    "for v, label, size in zip(layout, graph.vs[\"name\"], in_degrees):\n",
    "    shift = 0.002*size + 0.03  # Adjust the multiplier (0.1) to control the shift amount\n",
    "    ax.text(v[0], v[1] + shift, label, color='black', fontsize=15, ha='center', va='center', fontweight='heavy', path_effects=[withStroke(linewidth=1, foreground='black')])\n",
    "\n",
    "fig.set_size_inches(20, 20)\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'PLOTIPC2UNORM' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa73e3f",
   "metadata": {},
   "source": [
    "### Citations unnormalised yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a856a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "Storing_array = np.zeros((len(Present_IPCs_Keys),len(Present_Dates_Cit))) # Initialising empty storing array\n",
    "\n",
    "for y in tqdm(range(len(Present_Dates_Pat)-range_y)):\n",
    "    \n",
    "    range_y = 1 #Â Select 5 years\n",
    "    Years_Selected = Present_Dates_Pat[y:y+range_y]\n",
    "    Data_Y = Data.loc[Data['Source Patent Year'].isin(Years_Selected)]\n",
    "\n",
    "    # Graphing normalised\n",
    "\n",
    "    graph = ig.Graph(directed=True)\n",
    "    graph.add_vertices(Present_IPCs)\n",
    "    graph.add_edges(list(dict(Data_Y[['Source IPC','Target IPC']].value_counts()).keys()))\n",
    "    graph.simplify() # Remove self loops\n",
    "    to_delete_ids = [v.index for v in graph.vs if v.degree() == 0] # Delete isolated nodes\n",
    "    graph.delete_vertices(to_delete_ids)\n",
    "\n",
    "    # Adding weights\n",
    "    Counts_prelim = dict(Data_Y[['Source IPC','Target IPC']].value_counts())\n",
    "    graph.es['weight'] = list(Counts_prelim.values())\n",
    "\n",
    "    in_degrees = graph.degree(mode='in')\n",
    "    max_in_degrees = max(in_degrees)\n",
    "\n",
    "    extract_information = list(zip(list(graph.vs['name']),list(graph.vs['weight'])))\n",
    "\n",
    "    # Storing all values into the storing array\n",
    "    for j in range(len(extract_information)):\n",
    "        Storing_array[Present_IPCs_Keys[extract_information[j][0]]][y] = extract_information[j][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "Dates_plotting = np.arange(min(np.array(Present_Dates_Cit).astype(int)), max(np.array(Present_Dates_Cit).astype(int)) + 1) # Dates for plotting\n",
    "Colors = pl.cm.coolwarm(np.linspace(0, 1, len(Present_IPCs))) # Colors for plotting\n",
    "\n",
    "Most_Cited = []\n",
    "for i in range(len(Present_Dates_Cit)):\n",
    "    Most_Cited.append(list(Present_IPCs_Keys.keys())[np.argmax(Storing_array.T[i])])\n",
    "\n",
    "for k in range(len(Present_IPCs_Keys)):\n",
    "    if str(list(Present_IPCs_Keys.keys())[k]) in Most_Cited: # Filtering only the most relevant\n",
    "        translated = str(translate_ipc(list(Present_IPCs_Keys.keys())[k])[0])[:22] # Reducing to 22 characters\n",
    "        plt.scatter(Dates_plotting, Storing_array[k], color=Colors[k], s=20, label=f'{list(Present_IPCs_Keys.keys())[k]} : {translated}')\n",
    "\n",
    "for k in range(len(Dates_plotting)):\n",
    "    plt.axvline(x=Dates_plotting[k], color='black', linestyle=':', linewidth=0.5)\n",
    "    highest_point = max(Storing_array[:, k])  # Get the highest point for this instance\n",
    "    plt.text(Dates_plotting[k]-0.4, highest_point+0.15, Most_Cited[k], fontsize=12, zorder=20)\n",
    "    plt.scatter(Dates_plotting[k], highest_point, color=Colors[Present_IPCs_Keys[Most_Cited[k]]], s=200, zorder=10)  # Add a point at the highest point and set zorder to 10\n",
    "    \n",
    "plt.legend(loc='upper left', borderaxespad=0.1, fancybox=True, facecolor='white', frameon=True, framealpha=1, edgecolor='white') \n",
    "plt.title('Ratio of citations')\n",
    "plt.xlabel('Year', fontsize=15)\n",
    "plt.ylabel('Importance', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ceb2f",
   "metadata": {},
   "source": [
    "# Graphing normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929e63fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patheffects import withStroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ig.Graph(directed=True)\n",
    "graph.add_vertices(Present_IPCs)\n",
    "graph.add_edges(list(dict(Data[['Source IPC','Target IPC']].value_counts()).keys()))\n",
    "graph.simplify() # Remove self loops\n",
    "to_delete_ids = [v.index for v in graph.vs if v.degree() == 0] # Delete isolated nodes\n",
    "graph.delete_vertices(to_delete_ids)\n",
    "graph.delete_vertices('nan')\n",
    "\n",
    "# Adding weights\n",
    "Counts_prelim = dict(Data[['Source IPC','Target IPC']].value_counts())\n",
    "graph.es['weight'] = list(Counts_prelim.values())\n",
    "\n",
    "communities = graph.community_edge_betweenness(weights=graph.es['weight'])\n",
    "communities = communities.as_clustering()\n",
    "bridges = graph.bridges()\n",
    "\n",
    "in_degrees = graph.degree(mode='in')\n",
    "max_in_degrees = max(in_degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd4d1d",
   "metadata": {},
   "source": [
    "##### Normalising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables\n",
    "IPC_counts = pd.DataFrame(list(zip(list(dict(Data['Source IPC'].value_counts()).keys()),list(dict(Data['Source IPC'].value_counts()).values()))),columns=[['IPC','Count']])\n",
    "IPC_counts.to_clipboard()\n",
    "IPC_counts = pd.read_clipboard()\n",
    "IPC_in_degrees = pd.DataFrame(list(zip(list(graph.vs['name']),list(in_degrees))),columns=[['IPC','In Degrees']])\n",
    "IPC_in_degrees.to_clipboard()\n",
    "IPC_in_degrees = pd.read_clipboard()\n",
    "IPC_together = IPC_counts.merge(IPC_in_degrees, left_on='IPC', right_on='IPC')\n",
    "IPC_together = IPC_together[['Count','In Degrees']].astype(int)\n",
    "\n",
    "Count_Degree_Ratio = []\n",
    "for i in range(len(IPC_together)):\n",
    "    Count_Degree_Ratio.append(IPC_together['In Degrees'][i]/IPC_together['Count'][i])\n",
    "    \n",
    "graph.vs['CDR'] = np.array(Count_Degree_Ratio).astype(float)\n",
    "max_CDR = max(graph.vs['CDR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d41de7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a colormap for node colors\n",
    "colormap = plt.cm.get_cmap('coolwarm')  # Choose any colormap you like\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ig.plot(\n",
    "    graph,\n",
    "    layout=graph.layout(layout='reingold_tilford_circular'),\n",
    "    target=ax,\n",
    "    vertex_size=[s * 0.03 + 0.02 for s in graph.vs['CDR']],\n",
    "    mark_groups=True,\n",
    "    vertex_frame_width=1.0,\n",
    "    vertex_frame_color='white',\n",
    "    vlabel_size=10.0,\n",
    "    vertex_color=[colormap(d/max_CDR) for d in graph.vs['CDR']],\n",
    "    edge_width=[w*0.001 + 0.05 for w in graph.es['weight']],\n",
    "    vertex_label_color='white',\n",
    "    edge_color=[colormap(w/max(graph.es['weight'])) for w in graph.es['weight']],\n",
    "    edge_arrow_size=[w*0.0000005 + 0.001 for w in graph.es['weight']]\n",
    ")\n",
    "\n",
    "layout = graph.layout(layout='reingold_tilford_circular')\n",
    "\n",
    "for v, label, size in zip(layout, graph.vs[\"name\"], graph.vs[\"CDR\"]):\n",
    "    shift = 0.01*size + 0.05  # Adjust the multiplier (0.1) to control the shift amount\n",
    "    ax.text(v[0], v[1] + shift, label, color='black', fontsize=10, ha='center', va='center', fontweight='heavy', path_effects=[withStroke(linewidth=1, foreground='black')])\n",
    "    \n",
    "fig.set_size_inches(20, 20)\n",
    "\n",
    "#file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'PLOTIPC3' + \".png\"\n",
    "#plt.savefig(file_dir, dpi=300, transparent=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6032984",
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_ipc('H05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.vs['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea19de42",
   "metadata": {},
   "source": [
    "# Graphing Normalised Yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e34957",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Storing_array = np.zeros((len(Present_IPCs_Keys),len(Present_Dates_Cit))) # Initialising empty storing array\n",
    "\n",
    "range_y = 5 #Â Select 5 years\n",
    "\n",
    "for y in tqdm(range(len(Present_Dates_Pat)-range_y)):\n",
    "    \n",
    "    Years_Selected = Present_Dates_Pat[y:y+range_y]\n",
    "    Data_Y = Data.loc[Data['Source Patent Year'].isin(Years_Selected)]\n",
    "\n",
    "    # Graphing normalised\n",
    "\n",
    "    graph = ig.Graph(directed=True)\n",
    "    graph.add_vertices(Present_IPCs)\n",
    "    graph.add_edges(list(dict(Data_Y[['Source IPC','Target IPC']].value_counts()).keys()))\n",
    "    graph.simplify() # Remove self loops\n",
    "    to_delete_ids = [v.index for v in graph.vs if v.degree() == 0] # Delete isolated nodes\n",
    "    graph.delete_vertices(to_delete_ids)\n",
    "\n",
    "    # Adding weights\n",
    "    Counts_prelim = dict(Data_Y[['Source IPC','Target IPC']].value_counts())\n",
    "    graph.es['weight'] = list(Counts_prelim.values())\n",
    "\n",
    "    in_degrees = graph.degree(mode='in')\n",
    "    max_in_degrees = max(in_degrees)\n",
    "\n",
    "    ##### Normalising\n",
    "\n",
    "    # Tables\n",
    "    IPC_counts = pd.DataFrame(list(zip(list(dict(Data_Y['Source IPC'].value_counts()).keys()),list(dict(Data_Y['Source IPC'].value_counts()).values()))),columns=[['IPC','Count']])\n",
    "    IPC_counts.to_clipboard()\n",
    "    IPC_counts = pd.read_clipboard()\n",
    "    IPC_in_degrees = pd.DataFrame(list(zip(list(graph.vs['name']),list(in_degrees))),columns=[['IPC','In Degrees']])\n",
    "    IPC_in_degrees.to_clipboard()\n",
    "    IPC_in_degrees = pd.read_clipboard()\n",
    "    IPC_together = IPC_counts.merge(IPC_in_degrees, left_on='IPC', right_on='IPC')\n",
    "    IPC_together = IPC_together[['Count','In Degrees']].astype(int)\n",
    "\n",
    "    Count_Degree_Ratio = []\n",
    "    for i in range(len(IPC_together)):\n",
    "        Count_Degree_Ratio.append(IPC_together['In Degrees'][i]/IPC_together['Count'][i])\n",
    "\n",
    "    graph.vs['CDR'] = np.array(Count_Degree_Ratio).astype(float)\n",
    "    max_CDR = max(graph.vs['CDR'])\n",
    "\n",
    "    extract_information = list(zip(list(graph.vs['name']),list(graph.vs['CDR'])))\n",
    "\n",
    "    # Storing all values into the storing array\n",
    "    for j in range(len(extract_information)):\n",
    "        Storing_array[Present_IPCs_Keys[extract_information[j][0]]][y] = extract_information[j][1]\n",
    "        \n",
    "epsilon = 0.001 # To avoid error in logarithmic plot\n",
    "Storing_array[Storing_array == 0] = epsilon\n",
    "Storing_array = np.log(Storing_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f7c1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "Dates_plotting = np.arange(min(np.array(Present_Dates_Cit).astype(int)), max(np.array(Present_Dates_Cit).astype(int)) + 1) # Dates for plotting\n",
    "Colors = pl.cm.coolwarm(np.linspace(0, 1, len(Present_IPCs))) # Colors for plotting\n",
    "\n",
    "Most_Cited = []\n",
    "Least_Cited = []\n",
    "for i in range(len(Present_Dates_Cit)):\n",
    "    Most_Cited.append(list(Present_IPCs_Keys.keys())[np.argmax(Storing_array.T[i])])\n",
    "    Least_Cited.append(list(Present_IPCs_Keys.keys())[np.argmin(Storing_array.T[i])])\n",
    "\n",
    "for k in range(len(Present_IPCs_Keys)):\n",
    "    if str(list(Present_IPCs_Keys.keys())[k]) in Most_Cited: # Filtering only the most relevant\n",
    "        translated = str(translate_ipc(list(Present_IPCs_Keys.keys())[k])[0])[:22] # Reducing to 22 characters\n",
    "        plt.scatter(Dates_plotting, Storing_array[k], color=Colors[k], s=20, label=f'{list(Present_IPCs_Keys.keys())[k]} : {translated}')\n",
    "    if str(list(Present_IPCs_Keys.keys())[k]) in Least_Cited: # Filtering only the most relevant\n",
    "        translated = str(translate_ipc(list(Present_IPCs_Keys.keys())[k])[0])[:22] # Reducing to 22 characters\n",
    "        plt.scatter(Dates_plotting, Storing_array[k], color=Colors[k], s=20, label=f'{list(Present_IPCs_Keys.keys())[k]} : {translated}')\n",
    "\n",
    "for k in range(len(Dates_plotting)):\n",
    "    plt.axvline(x=Dates_plotting[k], color='black', linestyle=':', linewidth=0.5)\n",
    "    highest_point = max(Storing_array[:, k])  # Get the highest point for this instance\n",
    "    \n",
    "    plt.text(Dates_plotting[k]-0.4, highest_point+0.15, Most_Cited[k], fontsize=12, zorder=20)\n",
    "    plt.scatter(Dates_plotting[k], highest_point, color=Colors[Present_IPCs_Keys[Most_Cited[k]]], s=200, zorder=10)  # Add a point at the highest point and set zorder to 10\n",
    "    lowest_point = min(Storing_array[:, k])  # Get the highest point for this instance\n",
    "\n",
    "#plt.legend(loc='upper left', borderaxespad=0.1, fancybox=True, facecolor='white', frameon=True, framealpha=1, edgecolor='white') \n",
    "#plt.title('Ratio of citations')\n",
    "#plt.xlabel('Year', fontsize=15)\n",
    "plt.axhline(y=0, color='grey', linestyle='-', linewidth=1)\n",
    "plt.ylabel('Citation to count ratio (Logarithmic)', fontsize=15)\n",
    "plt.ylim(-5,3)\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'PLOT_5_YEARLY' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=False)\n",
    "#plt.yscale(\"log\");\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498fb885",
   "metadata": {},
   "source": [
    "# Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ig.Graph(directed=True)\n",
    "graph.add_vertices(Present_IPCs)\n",
    "graph.add_edges(list(dict(Data[['Source IPC','Target IPC']].value_counts()).keys()))\n",
    "graph.simplify() # Remove self loops\n",
    "to_delete_ids = [v.index for v in graph.vs if v.degree() == 0] # Delete isolated nodes\n",
    "graph.delete_vertices(to_delete_ids)\n",
    "graph.delete_vertices('nan')\n",
    "\n",
    "# Adding weights\n",
    "Counts_prelim = dict(Data[['Source IPC','Target IPC']].value_counts())\n",
    "graph.es['weight'] = list(Counts_prelim.values())\n",
    "\n",
    "communities = graph.community_edge_betweenness(weights=graph.es['weight'])\n",
    "communities = communities.as_clustering()\n",
    "bridges = graph.bridges()\n",
    "\n",
    "in_degrees = graph.degree(mode='in')\n",
    "max_in_degrees = max(in_degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4524663b",
   "metadata": {},
   "source": [
    "##### Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37648c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_div_mes(IPC_chosen):\n",
    "    \n",
    "    '''Diversity Measure'''\n",
    "    \n",
    "    IPC_spreads_all = dict(zip(list(Present_IPCs),np.zeros(len(Present_IPCs))))\n",
    "    IPC_spreads_all = dict(zip(list(Present_IPCs),np.zeros(len(Present_IPCs))))\n",
    "    IPC_spread_spec = Data[Data['Source IPC'] == IPC_chosen]['Target IPC'].value_counts()[1:] \n",
    "    IPC_spread_spec_keys = list(dict(IPC_spread_spec).keys())\n",
    "    IPC_spread_spec_values = list(dict(IPC_spread_spec).values())\n",
    "    for i in range(len(IPC_spread_spec_keys)):\n",
    "        IPC_spreads_all[IPC_spread_spec_keys[i]] = np.log(IPC_spread_spec_values[i])\n",
    "    diversity_spread = dict(sorted(IPC_spreads_all.items(), key = lambda x:x[1], reverse=True )) #Â The plot of diversity\n",
    "    best_fit_grad = list(np.poly1d(np.polyfit(np.arange(len(list(diversity_spread.values()))), list(diversity_spread.values()), 1)))[0] # Best fit line\n",
    "    \n",
    "    return (abs(1/(best_fit_grad+1))-1)*100, diversity_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724dede",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diversity_measures = []\n",
    "\n",
    "for k in range(len(list(graph.vs['name']))):\n",
    "    IPC_chosen = list(graph.vs['name'])[k]\n",
    "    diversity_measures.append(get_div_mes(IPC_chosen)[0])\n",
    "    \n",
    "graph.vs['div'] = diversity_measures\n",
    "max_div = max(graph.vs['div'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8089d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "associations_div_mes = list(zip(list(graph.vs['name']),list(diversity_measures)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b42127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a colormap for node colors\n",
    "colormap = plt.cm.get_cmap('coolwarm')  # Choose any colormap you like\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "ig.plot(\n",
    "    graph,\n",
    "    layout=graph.layout(layout='reingold_tilford_circular'),\n",
    "    target=ax,\n",
    "    vertex_size=[s * 0.1 + 0.05 for s in graph.vs['div']],\n",
    "    mark_groups=True,\n",
    "    vertex_frame_width=1.0,\n",
    "    vertex_frame_color='White',\n",
    "    vertex_label=graph.vs[\"name\"],\n",
    "    vlabel_size=10.0,\n",
    "    vertex_color=[colormap(d/max_div) for d in graph.vs['div']],\n",
    "    edge_width=[w*0.005 + 0.01 for w in graph.es['weight']],\n",
    "    vertex_label_color='White',\n",
    "    edge_color=[colormap(w/max(graph.es['weight'])) for w in graph.es['weight']],\n",
    "    edge_arrow_size=[w*0.00001 + 0.001 for w in graph.es['weight']]\n",
    ")\n",
    "\n",
    "fig.set_size_inches(20, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8becb424",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "IPC_s = 'F04'\n",
    "diversity_measure = np.array(get_div_mes(IPC_s)[0])\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "func_x = np.arange(len(list(get_div_mes(IPC_s)[1].values())))\n",
    "func_y = list(get_div_mes(IPC_s)[1].values())\n",
    "names = list(get_div_mes(IPC_s)[1].keys())\n",
    "plt.scatter(func_x,func_y, color='white')\n",
    "\n",
    "i=0\n",
    "for x, y in zip(func_x, func_y):\n",
    "    plt.vlines(x, 0, y, linestyle='-', colors='white', alpha=0.5)\n",
    "    plt.text(x-0.3, y+0.2, names[i], rotation=90,color='white')\n",
    "    i+=1\n",
    "\n",
    "plt.axis('off')\n",
    "#plt.legend(frameon=False,fontsize=12)\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'plotsEXAMPLEIPCDIV2' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7a580",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "topx=10\n",
    "top_div = dict(sorted(dict(zip(graph.vs['name'],graph.vs['div'])).items(), key=lambda x:x[1], reverse=True)[:topx])\n",
    "top_div_IPCs = list(top_div.keys())\n",
    "top_div_values = list(top_div.values())\n",
    "\n",
    "i=0\n",
    "for ipc in top_div_IPCs:\n",
    "    print(sorted(graph.vs['div'],reverse=True)[i])\n",
    "    i+=1\n",
    "    print(ipc)\n",
    "    print(list(translate_ipc(ipc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af04ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottomx=10\n",
    "bottom_div = dict(sorted(dict(zip(graph.vs['name'],graph.vs['div'])).items(), key=lambda x:x[1], reverse=True)[-bottomx:])\n",
    "bottom_div_IPCs = list(bottom_div.keys())\n",
    "bottom_div_values = list(bottom_div.values())\n",
    "\n",
    "for ipc in bottom_div_IPCs:\n",
    "    print(ipc,translate_ipc(ipc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5c3424",
   "metadata": {},
   "source": [
    "# Evolution of patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c9b40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patents_ind = (Patents[['Application','Patent Year']].drop_duplicates()).astype(str)\n",
    "year_selected = 2001\n",
    "Patents_cumu = 0\n",
    "Patents_cumu_ar = []\n",
    "Patents_increase = 0\n",
    "Patents_increase_ar = []\n",
    "\n",
    "for i in range(len(Present_Dates_Pat)):\n",
    "    Patents_increase = len(Patents_ind.loc[Patents_ind['Patent Year'] == str(Present_Dates_Pat[i])])\n",
    "    Patents_cumu += Patents_increase\n",
    "    Patents_increase_ar.append(Patents_increase)\n",
    "    Patents_cumu_ar.append(Patents_cumu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16386e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "Dates_plotting = np.arange(min(np.array(Present_Dates_Pat).astype(int)), max(np.array(Present_Dates_Pat).astype(int)) + 1) # Dates for plotting\n",
    "Colors = pl.cm.coolwarm(np.linspace(0, 1, len(Present_IPCs))) # Colors for plotting\n",
    "\n",
    "#plt.plot(Dates_plotting,Patents_cumu_ar,color='black')\n",
    "plt.plot(Dates_plotting,Patents_increase_ar,color='black')\n",
    "\n",
    "#plt.legend(loc='upper right', borderaxespad=0.1, fancybox=True, facecolor='white', frameon=True, framealpha=1, edgecolor='white') \n",
    "plt.xlabel('Year', fontsize=15)\n",
    "plt.ylabel('Number of citations occurring for designated year', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cf494b",
   "metadata": {},
   "source": [
    "# Normalised share of patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877512f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Storing_array = np.zeros((len(Present_IPCs_Keys),len(Present_Dates_Pat))) # Initialising empty storing array\n",
    "\n",
    "for i in range(len(Present_Dates_Pat)):\n",
    "    \n",
    "    # Creating IPC Citation relationships\n",
    "    Data_select = Data.loc[Data['Citation Year'] == Present_Dates_Pat[i]] # Selecting all patents created in specific year\n",
    "    Counts_prelim = dict(Data_select[['Source IPC','Target IPC']].value_counts()) # Converting multiple citation counts into weights\n",
    "    Counts = [(key[0], key[1], value) for key, value in Counts_prelim.items()] # Formatted correctly\n",
    "    \n",
    "    # Creating graph\n",
    "    graph = nx.DiGraph()\n",
    "    graph.add_weighted_edges_from(Counts)\n",
    "    graph.remove_edges_from(nx.selfloop_edges(graph)) # NOT ACCOUNTING FOR SELF CITATIONS\n",
    "    extract_information = list(graph.in_degree(weight='weight')) # Accounting for the counts\n",
    "    \n",
    "    # Storing all values into the storing array\n",
    "    for j in range(len(extract_information)):\n",
    "        Storing_array[Present_IPCs_Keys[extract_information[j][0]]][i] = extract_information[j][1]\n",
    "\n",
    "for i in range(len(Storing_array.T)):\n",
    "    if np.sum(Storing_array.T[i]) != 0:\n",
    "        Storing_array.T[i] = Storing_array.T[i]/(np.sum(Storing_array.T[i]))\n",
    "        \n",
    "plt.figure(figsize=(20, 5))\n",
    "Dates_plotting = np.arange(min(np.array(Present_Dates_Pat).astype(int)), max(np.array(Present_Dates_Pat).astype(int)) + 1) # Dates for plotting\n",
    "Colors = pl.cm.coolwarm(np.linspace(0, 1, len(Present_IPCs))) # Colors for plotting\n",
    "\n",
    "Most_Cited = []\n",
    "for i in range(len(Present_Dates_Pat)):\n",
    "    Most_Cited.append(list(Present_IPCs_Keys.keys())[np.argmax(Storing_array.T[i])])\n",
    "\n",
    "plt.stackplot(Dates_plotting,Storing_array,labels=Present_IPCs_Keys.keys(),colors = Colors)\n",
    "\n",
    "for k in range(len(Dates_plotting)):\n",
    "    plt.axvline(x=Dates_plotting[k], color='black', linestyle=':', linewidth=0.5)\n",
    "    #highest_point = 2  # Get the highest point for this instance\n",
    "    #plt.text(Dates_plotting[k], 1+0.01, Most_Cited[k], fontsize=12, zorder=20, color='Black')  # Adjust the y coordinate to move the text above the highest point and set zorder to 10\n",
    "    #plt.scatter(Dates_plotting[k], highest_point, color=Colors[Present_IPCs_Keys[Most_Cited[k]]], s=200, zorder=10)  # Add a point at the highest point and set zorder to 10\n",
    "\n",
    "plt.legend(loc='upper right', borderaxespad=0.1, fancybox=True, facecolor='white', frameon=True, framealpha=1, edgecolor='white') \n",
    "#plt.xlabel('Year', fontsize=15)\n",
    "#plt.ylabel('Number of citations occurring for designated year', fontsize=15)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b3217",
   "metadata": {},
   "source": [
    "# Fix from EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Citation Year'] = Data['Citation Year'].astype(int)\n",
    "Data['Source Patent Year'] = Data['Source Patent Year'].astype(int)\n",
    "Data['Target Year'] = Data['Target Patent Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67ec051",
   "metadata": {},
   "outputs": [],
   "source": [
    "Citations_unfiltered = Data[['Source','Target','Citation Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_EPO_patents = list(set(list(Data['Source'])+list(Data['Target'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2089c435",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patents_for_EPO = pd.concat([Data[['Source','Source IPC','Source Region','Source Patent Year']], Data[['Target','Target IPC','Target Region','Target Patent Year']].rename(columns={'Target':'Source','Target IPC':'Source IPC','Target Region':'Source Region','Target Patent Year':'Source Patent Year'})], axis=0)\n",
    "Patents_for_EPO = Patents_for_EPO.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc61d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patents_for_EPO = Patents_for_EPO.rename(columns={'Source':'Application','Region':'Region','Source Patent Year':'Patent Year','Source IPC':'IPC'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934d6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Patents = Patents_for_EPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08df6ae1",
   "metadata": {},
   "source": [
    "# 3D Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b522eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Source IPC'] = Data['Source IPC'].str.replace(\" \", \"\")\n",
    "Data['Target IPC'] = Data['Target IPC'].str.replace(\" \", \"\")\n",
    "Patents['IPC'] = Patents['IPC'].str.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ef105",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Citations_unfiltered = Citations_raw.rename(columns={'source':'Source','target':'Target','time':'Citation Year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53800a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "graph.add_edges_from(list(zip(list(Citations_unfiltered['Source']),list(Citations_unfiltered['Target']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patents = list(graph.nodes())\n",
    "\n",
    "dates_for_patents = dict(list(zip(list(Citations_unfiltered['Source']),list((Citations_unfiltered['Citation Year'])))))\n",
    "nx.set_node_attributes(graph, 1970, name=\"date\")\n",
    "nx.set_node_attributes(graph, dates_for_patents, name=\"date\")\n",
    "\n",
    "IPC_for_pat = Patents[['Application','IPC']].drop_duplicates()\n",
    "IPC_for_pat = IPC_for_pat.groupby('Application')['IPC'].apply(', '.join).reset_index()\n",
    "IPC_codes = dict(list(zip(list(IPC_for_pat['Application']),list(IPC_for_pat['IPC']))))\n",
    "nx.set_node_attributes(graph, ' ', name=\"IPC\")\n",
    "nx.set_node_attributes(graph, IPC_codes, name=\"IPC\")\n",
    "\n",
    "graph_orig = graph\n",
    "ccs = sorted(nx.connected_components(graph_orig), key=len, reverse=True)\n",
    "largest_ccs = graph_orig.subgraph(ccs[0])\n",
    "graph = largest_ccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6129244",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_spring = nx.kamada_kawai_layout(graph)\n",
    "pos = {list(graph.nodes())[i]: (list(dict(pos_spring).values())[i][0], list(nx.get_node_attributes(graph, 'date').values())[i], list(dict(pos_spring).values())[i][1]) for i in tqdm(range(len(graph.nodes)))}\n",
    "nx.set_node_attributes(graph, pos, name=\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d1515",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47113795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_plot_3D(G, angle, save):\n",
    "\n",
    "    # extracting info\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    n = G.number_of_nodes()\n",
    "    dates = list(nx.get_node_attributes(G, 'date').values())\n",
    "    IPCs = list(nx.get_node_attributes(G, 'IPC').values())\n",
    "    \n",
    "    # get shortest path\n",
    "    node_dates = nx.get_node_attributes(G, name=\"date\")\n",
    "    lowest_date_node = min(node_dates, key=node_dates.get)\n",
    "    highest_date_node = max(node_dates, key=node_dates.get)\n",
    "    path_nodes = nx.shortest_path(G,source=lowest_date_node,target=highest_date_node)\n",
    "    \n",
    "    with plt.style.context(('ggplot')):\n",
    "        \n",
    "        fig = plt.figure(figsize=(20,15))\n",
    "        ax = fig.gca(projection='3d',facecolor='white')\n",
    "        \n",
    "        jcounter = 0\n",
    "        for key, value in pos.items(): # nodes\n",
    "            xi = value[0]\n",
    "            yi = value[1]\n",
    "            zi = value[2]\n",
    "            relative_output = (10+10*G.degree(key)) # Highlight only those with known IPC\n",
    "            #relative_output = (10+100*G.out_degree(key))/(1+10*abs(max(dates)-value[1])) \n",
    "            #if IPCs[jcounter] != 'N/A':\n",
    "            ax.scatter(xi, yi, zi, c=value[1], norm=mpl.colors.Normalize(vmin=min(dates),vmax=max(dates)), cmap = 'coolwarm', s=relative_output, edgecolors='k', alpha=0.9, zorder=10) # Out degree since those CITE the most\n",
    "                #ax.text(xi, yi, zi+0.1, s=IPCs[jcounter], c='white', fontsize=7, zorder=20)\n",
    "            #else:\n",
    "                #ax.scatter(xi, yi, zi, c=value[1], norm=mpl.colors.Normalize(vmin=min(dates),vmax=max(dates)), cmap = 'coolwarm', s=relative_output, edgecolors='k', alpha=0.45, zorder=10) # Out degree since those CITE the most\n",
    "            \n",
    "            ax.plot(np.array((xi,xi)), np.array((yi,yi)), np.array((-1,zi)), c='white', alpha=0.5, linewidth=0.5, linestyle=':')\n",
    "            \n",
    "            jcounter += 1\n",
    "            \n",
    "        c_selection = mpl.cm.coolwarm(np.linspace(0,1,int(abs(max(dates)-min(dates)))+1)) # Edge Colors\n",
    "        \n",
    "        for i,j in enumerate(G.edges()): # edges\n",
    "            x = np.array((pos[j[0]][0], pos[j[1]][0]))\n",
    "            y = np.array((pos[j[0]][1], pos[j[1]][1]))\n",
    "            z = np.array((pos[j[0]][2], pos[j[1]][2]))\n",
    "            \n",
    "            if pos[j[0]][1] < 1970:\n",
    "                print('occuring 1')\n",
    "                ax.plot(x, np.array((1970, pos[j[1]][1])), z, c=c_selection[int(abs(pos[j[1]][1]-min(dates)))], alpha=0.1, linewidth=0.5)\n",
    "            if pos[j[1]][1] < 1970:\n",
    "                print('occuring 2')\n",
    "                ax.plot(x, np.array((pos[j[0]][1], 1970)), z, c=c_selection[int(abs(pos[j[1]][1]-min(dates)))], alpha=0.1, linewidth=0.5)\n",
    "            else:\n",
    "                ax.plot(x, y, z, c=c_selection[int(abs(pos[j[1]][1]-min(dates)))], alpha=0.5, linewidth=0.5)\n",
    "            #ax.quiver(x[1], y[1], z[1], x[0]-x[1], y[0]-y[1], z[0]-z[1], color=c_selection[int(abs(pos[j[1]][1]-min(dates)))], alpha=0.5, linewidth=0.5)\n",
    "            \n",
    "    # viewpoint\n",
    "    #ax.axes.set_ylim3d(bottom=1970, top=2017) \n",
    "    ax.axes.set_zlim3d(bottom=-1, top=1) \n",
    "    \n",
    "    ax.w_xaxis.set_pane_color((0.33, 0.33, 0.33, 1.0))\n",
    "    ax.w_yaxis.set_pane_color((0.33, 0.33, 0.33, 1.0))\n",
    "    ax.w_zaxis.set_pane_color((0.33, 0.33, 0.33, 1.0))\n",
    "    \n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] = mpl.colors.to_rgba('lightgrey', alpha=0.3)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] = mpl.colors.to_rgba('lightgrey', alpha=0.3)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] = mpl.colors.to_rgba('lightgrey', alpha=0.3)\n",
    "    \n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True, nbins=30))\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_zticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "\n",
    "    ax.set_box_aspect([1,3,1])\n",
    "    ax.view_init(30, angle)\n",
    "            \n",
    "    if save is not False:\n",
    "        file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\"+'3DPLOT1'+\".png\"\n",
    "        plt.savefig(file_dir, dpi=300)\n",
    "        plt.close(\"all\")\n",
    "        print('Done.')\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a66175f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network_plot_3D(graph, 155, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51840766",
   "metadata": {},
   "source": [
    "# Visible clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [graph_orig.subgraph(c).copy() for c in nx.connected_components(graph_orig)]\n",
    "S_sorted = sorted(S, key=lambda g: len(g.nodes()), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d6e9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(21, 14))\n",
    "ax = axes.flatten()  # Flatten the 2D array of axes for easy access\n",
    "\n",
    "for i in range(6):\n",
    "    graph = S_sorted[i]\n",
    "    graph = nx.Graph(graph)\n",
    "    dates_for_cluster = nx.get_node_attributes(graph, 'date').values()\n",
    "    min_date_value = min(dates_for_cluster)\n",
    "    max_date_value = max(dates_for_cluster)\n",
    "    values_of_dates = dict(pd.DataFrame(dates_for_cluster).astype(int).value_counts())\n",
    "\n",
    "    ax[i].hist(dates_for_cluster, bins=len(np.arange(min_date_value, max_date_value)), color='black')\n",
    "    # ax[i].set_title(f'Cluster {i+1} Dates Histogram')\n",
    "    ax[i].set_ylabel('Count')\n",
    "    ax[i].set_ylim(0, 50)\n",
    "    ax[i].set_xlim(1979, 2020)\n",
    "    ax[i].xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax[i].yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax[i].locator_params(axis='x', nbins=20)\n",
    "    ax[i].locator_params(axis='y', nbins=20)\n",
    "    ax[i].grid(True, which='both', linestyle='-', linewidth=0.5, color='lightgrey', alpha=0.6)\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\"+'barplots'+\".png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_dir, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5eaee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a 2x2 grid of subplots\n",
    "colormap = plt.cm.get_cmap('coolwarm_r')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(42, 28))\n",
    "\n",
    "for i in range(6):\n",
    "    graph = S_sorted[i]\n",
    "    graph = nx.Graph(graph)\n",
    "    graph.remove_edges_from(nx.selfloop_edges(graph))\n",
    "    \n",
    "    pos_spring = nx.kamada_kawai_layout(graph)\n",
    "    date_label_pos = {node: (x, y + 0.05) for node, (x, y) in pos_spring.items()}\n",
    "    ipc_label_pos = {node: (x, y - 0.05) for node, (x, y) in pos_spring.items()}\n",
    "    \n",
    "    dates = list(nx.get_node_attributes(graph, 'date').values())\n",
    "    dates_arranged = sorted(list(set(dates))[1:])\n",
    "    date_labels = {node: date for node, date in zip(graph.nodes(), dates)}\n",
    "    \n",
    "    min_date_value = min(dates_arranged)\n",
    "    max_date_value = max(dates_arranged)\n",
    "    min_date_nodes = [node for node, date in date_labels.items() if date < min_date_value]\n",
    "    \n",
    "    ipcs = list(nx.get_node_attributes(graph, 'IPC').values())\n",
    "    ipc_labels = {node: date for node, date in zip(graph.nodes(), ipcs)}\n",
    "    \n",
    "    normalized_dates = [(date - min_date_value) / (max(dates_arranged) - min_date_value) for date in dates]\n",
    "    node_colors = [colormap(norm_date) for node, norm_date in zip(graph.nodes(), normalized_dates)]\n",
    "    \n",
    "    nx.draw(graph,\n",
    "            pos=pos_spring, \n",
    "            with_labels=False,\n",
    "            node_color=node_colors,\n",
    "            cmap=colormap, \n",
    "            edge_color='lightgrey',\n",
    "            node_size=[30 if node in min_date_nodes else 10 for node in graph.nodes()],\n",
    "            width=1,\n",
    "            arrowsize=10,\n",
    "            font_color=\"black\",\n",
    "            font_size=5,\n",
    "            ax=axes[i // 3, i % 3])\n",
    "    \n",
    "    #nx.draw_networkx_labels(graph, date_label_pos, date_labels, font_size=10, font_color='black', ax=axes[i // 3, i % 3])\n",
    "    #nx.draw_networkx_labels(graph, ipc_label_pos, ipc_labels, font_size=10, font_color='black', ax=axes[i // 3, i % 3])\n",
    "    \n",
    "    avg_clustering_coefficient = nx.average_clustering(graph)\n",
    "    avg_clustering_coefficient = 0 \n",
    "    if avg_clustering_coefficient > 0:\n",
    "        axes[i // 3, i % 3].text(0.8, 0.9, f'Average Clustering: {avg_clustering_coefficient:.3f}', \n",
    "                                transform=axes[i // 3, i % 3].transAxes,\n",
    "                                fontsize=10, ha='right', va='center', bbox=dict(facecolor='white', alpha=0))\n",
    "    \n",
    "    # Add the smallest and largest dates at the top of the plot\n",
    "    axes[i // 3, i % 3].text(0.9, 1, f'{min_date_value} â {max_date_value}', \n",
    "                            transform=axes[i // 3, i % 3].transAxes,\n",
    "                            fontsize=10, ha='center', va='center')\n",
    "    \n",
    "    axes[i // 3, i % 3].set_aspect('equal')\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\"+'multiplotsDATED'+\".png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_dir, dpi=300, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652faef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a 2x2 grid of subplots\n",
    "colormap = plt.cm.get_cmap('coolwarm_r')\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(30, 20))\n",
    "\n",
    "for i in range(6):\n",
    "    graph = S_sorted[i]\n",
    "    graph = nx.Graph(graph)\n",
    "    graph.remove_edges_from(nx.selfloop_edges(graph))\n",
    "    \n",
    "    pos_spring = nx.kamada_kawai_layout(graph)\n",
    "    date_label_pos = {node: (x, y + 0.05) for node, (x, y) in pos_spring.items()}\n",
    "    ipc_label_pos = {node: (x, y - 0.05) for node, (x, y) in pos_spring.items()}\n",
    "    \n",
    "    dates = list(nx.get_node_attributes(graph, 'date').values())\n",
    "    dates_arranged = sorted(list(set(dates))[1:])\n",
    "    date_labels = {node: date for node, date in zip(graph.nodes(), dates)}\n",
    "    \n",
    "    min_date_value = min(dates_arranged)\n",
    "    max_date_value = max(dates_arranged)\n",
    "    min_date_nodes = [node for node, date in date_labels.items() if date < min_date_value]\n",
    "    \n",
    "    ipcs = list(nx.get_node_attributes(graph, 'IPC').values())\n",
    "    ipc_labels = {node: date for node, date in zip(graph.nodes(), ipcs)}\n",
    "    \n",
    "    normalized_dates = [(date - min_date_value) / (max(dates_arranged) - min_date_value) for date in dates]\n",
    "    node_colors = [colormap(norm_date) for node, norm_date in zip(graph.nodes(), normalized_dates)]\n",
    "    node_colors = [(1,1,0,1) if node in biotech_patents_EPO else 'lightgrey' for node in graph.nodes()]\n",
    "    \n",
    "    nx.draw(graph,\n",
    "            pos=pos_spring, \n",
    "            with_labels=False,\n",
    "            node_color=node_colors,\n",
    "            cmap=colormap, \n",
    "            edge_color='lightgrey',\n",
    "            node_size=[40 if node in min_date_nodes else 20 for node in graph.nodes()],\n",
    "            width=1.5,\n",
    "            arrowsize=10,\n",
    "            font_color=\"white\",\n",
    "            font_size=5,\n",
    "            ax=axes[i // 3, i % 3])\n",
    "    \n",
    "    #nx.draw_networkx_labels(graph, date_label_pos, date_labels, font_size=10, font_color='black', ax=axes[i // 3, i % 3])\n",
    "    #nx.draw_networkx_labels(graph, ipc_label_pos, ipc_labels, font_size=10, font_color='black', ax=axes[i // 3, i % 3])\n",
    "    \n",
    "    avg_clustering_coefficient = nx.average_clustering(graph)\n",
    "    avg_clustering_coefficient = 0 \n",
    "    if avg_clustering_coefficient > 0:\n",
    "        axes[i // 3, i % 3].text(0.8, 0.9, f'Average Clustering: {avg_clustering_coefficient:.3f}', \n",
    "                                transform=axes[i // 3, i % 3].transAxes,\n",
    "                                fontsize=10, ha='right', va='center', bbox=dict(facecolor='white', alpha=0))\n",
    "    \n",
    "    # Add the smallest and largest dates at the top of the plot\n",
    "    axes[i // 3, i % 3].text(0.9, 1, f'{min_date_value} â {max_date_value}', \n",
    "                            transform=axes[i // 3, i % 3].transAxes,\n",
    "                            fontsize=10, ha='center', va='center', color='white')\n",
    "    \n",
    "    axes[i // 3, i % 3].set_aspect('equal')\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\"+'multiplotsALT3'+\".png\"\n",
    "plt.tight_layout()\n",
    "plt.savefig(file_dir, dpi=300, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight if biotech! reduce IPC number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f669e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "biotech_classes = [\n",
    "    'A01H1',\n",
    "    'A01H4',\n",
    "    'A01K67',\n",
    "    'A61K48',\n",
    "    'C12M',\n",
    "    'C12N',\n",
    "    'C12P',\n",
    "    'C12Q',\n",
    "    'G01N27/327',\n",
    "    'C07K4',\n",
    "    'C07K14', \n",
    "    'C07K16',\n",
    "    'C07K17',\n",
    "    'C07K19',\n",
    "    'C40B10',\n",
    "    'G01N3353',\n",
    "    'G01N3354',\n",
    "    'G01N3355',\n",
    "    'G01N3357',\n",
    "    'G01N3368',\n",
    "    'G01N3374',\n",
    "    'G01N3376',\n",
    "    'G01N3378',\n",
    "    'G01N3388',\n",
    "    'G01N3392',\n",
    "    'C07G11', \n",
    "    'C07G13', \n",
    "    'C07G15',\n",
    "    'C02F3/34',\n",
    "    'A61K38',\n",
    "    'A61K39',\n",
    "    'C40B50/06',\n",
    "    'A61K35/12', 'A61K35/13', 'A61K35/14', 'A61K35/15', 'A61K35/16', 'A61K35/17', 'A61K35/18', 'A61K35/19', 'A61K35/20', 'A61K35/21', 'A61K35/22', 'A61K35/23', 'A61K35/24', 'A61K35/25', 'A61K35/26', 'A61K35/27', 'A61K35/28', 'A61K35/29', 'A61K35/30', 'A61K35/31', 'A61K35/32', 'A61K35/33', 'A61K35/34', 'A61K35/35', 'A61K35/36', 'A61K35/37', 'A61K35/38', 'A61K35/39', 'A61K35/40', 'A61K35/41', 'A61K35/42', 'A61K35/43', 'A61K35/44', 'A61K35/45', 'A61K35/46', 'A61K35/47', 'A61K35/48', 'A61K35/49', 'A61K35/50', 'A61K35/51', 'A61K35/52', 'A61K35/53', 'A61K35/54', 'A61K35/55', 'A61K35/56', 'A61K35/57', 'A61K35/58', 'A61K35/59', 'A61K35/60', 'A61K35/61', 'A61K35/62', 'A61K35/63', 'A61K35/64', 'A61K35/65', 'A61K35/66', 'A61K35/67', 'A61K35/68', 'A61K35/69', 'A61K35/70', 'A61K35/71', 'A61K35/72', 'A61K35/73', 'A61K35/74', 'A61K35/75', 'A61K35/76', 'A61K35/77', 'A61K35/78', 'A61K35/79',\n",
    "    'C40B40/02', 'C40B40/03', 'C40B40/04', 'C40B40/05', 'C40B40/06', 'C40B40/07', 'C40B40/08',\n",
    "    'G06F19/10', 'G06F19/11', 'G06F19/12', 'G06F19/13', 'G06F19/14', 'G06F19/15', 'G06F19/16', 'G06F19/17', 'G06F19/18',\n",
    "    'G06F19/20', 'G06F19/21', 'G06F19/22', 'G06F19/23', 'G06F19/24'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0da6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#biotech_classes = [\"A01H001\", \"A01H004\", \"A01K067\", \"A01K035/12\", \"A01K035/13\", \"A01K035/14\",\"A01K035/15\", \"A01K035/16\", \"A01K035/17\", \"A01K035/18\", \"A01K035/19\", \"A01K035/20\", \"A01K035/21\", \"A01K035/22\", \"A01K035/23\", \"A01K035/24\", \"A01K035/25\", \"A01K035/26\", \"A01K035/27\", \"A01K035/28\", \"A01K035/29\", \"A01K035/30\", \"A01K035/31\", \"A01K305/32\", \"A01K035/33\", \"A01K035/34\", \"A01K035/35\", \"A01K035/36\", \"A01K035/37\", \"A01K035/38\", \"A01K035/39\", \"A01K035/40\", \"A01K035/41\", \"A01K035/42\", \"A01K035/43\", \"A01K035/44\", \"A01K035/45\", \"A01K035/46\", \"A01K035/47\", \"A01K035/48\", \"A01K035/49\", \"A01K035/50\", \"A01K035/51\", \"A01K035/52\", \"A01K035/53\", \"A01K035/54\", \"A01K035/55\", \"A01K035/56\", \"A01K035/57\", \"A01K035/58\", \"A01K035/59\", \"A01K035/60\", \"A01K035/61\", \"A01K035/62\", \"A01K035/63\", \"A01K035/64\", \"A01K035/65\", \"A01K035/66\", \"A01K035/67\", \"A01K035/68\", \"A01K035/69\", \"A01K035/70\", \"A01K035/71\", \"A01K035/72\", \"A01K035/73\", \"A01K035/74\", \"A01K035/75\", \"A01K035/76\", \"A01K035/77\", \"A01K035/78\", \"A01K035/79\", \"A61K38\", \"A61K039\", \"A16K048\", \"C02F003/34\", \"C07G011\", \"C07G013\", \"C07G015\", \"C07K004\", \"C07K014\", \"C07K016\", \"C07K017\", \"C07K019\", \"C12M\", \"C12N\", \"C12P\", \"C12Q\", \"C40B010\", \"C40B040/02\", \"C40B040/03\",\"C40B040/04\", \"C40B040/05\", \"C40B040/06\", \"C40B040/07\", \"C40B040/08\", \"C40B050/06\", \"G01N027/327\", \"G01N033/53\", \"G01N033/54\", \"G01N033/55\", \"G01N033/57\", \"G01N033/68\", \"G01N033/74\", \"G01N033/76\", \"G01N033/78\", \"G01N033/88\", \"G01N033/92\", \"G06F019/10\",\"G06F019/11\", \"G06F019/12\", \"G06F019/13\", \"G06F019/14\", \"G06F019/15\", \"G06F019/16\", \"G06F019/17\", \"G06F019/18\", \"G06F019/20\", \"G06F019/21\", \"G06F019/22\", \"G06F019/23\", \"G06F019/24\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99233685",
   "metadata": {},
   "source": [
    "The following section is particularly messy and many imports are repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b4127b",
   "metadata": {},
   "source": [
    "# New EPO VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "biotech_pd=pd.DataFrame()\n",
    "for i in tqdm(range(len(biotech_classes))):\n",
    "    filt_for_type = EPO_IPCs['IPC'].str.contains('^'+biotech_classes[i]).fillna(False)\n",
    "    biotech_spec = EPO_IPCs.loc[filt_for_type]\n",
    "    biotech_pd = pd.concat([biotech_pd, biotech_spec], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a398bf",
   "metadata": {},
   "source": [
    "#### EPO VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPO_IPCs = pd.read_csv('/Users/joebacchus/Desktop/CASA/Data Original/Patent data/202001_EPO_IPC.txt', sep='|')\n",
    "EPO_IPCs = EPO_IPCs[['appln_id','IPC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9987e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPO_PATENTS = pd.read_csv('/Users/joebacchus/Desktop/CASA/Data Original/Patent data/202001_EPO_Inventor_reg.txt',sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93f380",
   "metadata": {},
   "outputs": [],
   "source": [
    "biotech_pd=pd.DataFrame()\n",
    "for i in tqdm(range(len(biotech_classes))):\n",
    "    filt_for_type = EPO_IPCs['IPC'].str.contains('^'+biotech_classes[i]).fillna(False)\n",
    "    biotech_spec = EPO_IPCs.loc[filt_for_type]\n",
    "    biotech_pd = pd.concat([biotech_pd, biotech_spec], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df10ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "biotech_patents_EPO = list(set(list(EPO_PATENTS.merge(biotech_pd, left_on = 'appln_id', right_on = 'appln_id')['app_nbr'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8ebff7",
   "metadata": {},
   "source": [
    "#### PCT VERSION (REDUNDENT!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_IPCs = pd.read_csv('/Users/joebacchus/Desktop/CASA/Data Original/Patent data/202001_PCT_IPC.txt', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24236961",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPO_PCT = pd.read_csv('/Users/joebacchus/Desktop/CASA/Data Original/Patent data/202001_EPO_PCT.txt', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCT_IPC_USE = EPO_PCT.merge(PCT_IPCs)[['app_nbr','IPC']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0c2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "biotech_pd=pd.DataFrame()\n",
    "for i in tqdm(range(len(biotech_classes))):\n",
    "    filt_for_type = PCT_IPC_USE['IPC'].str.contains('^'+biotech_classes[i]).fillna(False)\n",
    "    biotech_spec = PCT_IPC_USE.loc[filt_for_type]\n",
    "    biotech_pd = pd.concat([biotech_pd, biotech_spec], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "biotech_patents_PCT = list(set(list(biotech_pd['app_nbr'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79945682",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(biotech_patents_PCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(biotech_patents_EPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3af491",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.get_cmap('coolwarm_r')\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "\n",
    "graph = S_sorted[3] # Select the biotech one\n",
    "graph = nx.Graph(graph)\n",
    "\n",
    "pos_spring = nx.kamada_kawai_layout(graph)\n",
    "date_label_pos = {node: (x, y + 0.02) for node, (x, y) in pos_spring.items()}\n",
    "ipc_label_pos = {node: (x, y - 0.05) for node, (x, y) in pos_spring.items()}\n",
    "\n",
    "dates = list(nx.get_node_attributes(graph, 'date').values())\n",
    "dates_arranged = sorted(dates)\n",
    "date_labels = {node: date for node, date in zip(graph.nodes(), dates)}\n",
    "\n",
    "min_date_value = min(dates_arranged)\n",
    "max_date_value = max(dates_arranged)\n",
    "min_date_nodes = [node for node, date in date_labels.items() if date == min_date_value]\n",
    "\n",
    "ipcs = list(nx.get_node_attributes(graph, 'IPC').values())\n",
    "ipc_labels = {node: date for node, date in zip(graph.nodes(), ipcs)}\n",
    "\n",
    "normalized_dates = [(date - min_date_value) / (max(dates_arranged) - min_date_value) for date in dates]\n",
    "node_colors = [colormap(norm_date) for node, norm_date in zip(graph.nodes(), normalized_dates)]\n",
    "nodeedge_colors = [(0.33, 0.33, 0.33, 1) if node in biotech_patents_EPO else 'lightgrey' for node in graph.nodes()]\n",
    "node_labels = ['+' if node in biotech_patents_EPO else '' for node in graph.nodes()]\n",
    "#nodeedge_colors = [colormap(norm_date) for node, norm_date in zip(graph.nodes(), normalized_dates)]\n",
    "\n",
    "nx.draw(graph,\n",
    "        pos=pos_spring, \n",
    "        with_labels=False,\n",
    "        node_color=node_colors,\n",
    "        cmap=colormap, \n",
    "        edge_color='lightgrey',\n",
    "        #edgecolors=nodeedge_colors,\n",
    "        node_size=[80 if node in min_date_nodes else 40 for node in graph.nodes()],\n",
    "        width=2,\n",
    "        arrowsize=10,\n",
    "        labels=node_labels,\n",
    "        font_color=\"black\",\n",
    "        font_size=5)\n",
    "\n",
    "#nx.draw_networkx_labels(graph, pos=date_label_pos, font_size=5, font_color='black')\n",
    "\n",
    "#nodes.set_edgecolor([(0.33, 0.33, 0.33, 1.0) if node in biotech_patents_EPO else 'lightgrey' for node in graph.nodes()])\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "avg_clustering_coefficient = nx.average_clustering(graph)\n",
    "avg_clustering_coefficient = 0 \n",
    "if avg_clustering_coefficient > 0:\n",
    "    plt.text(0.8, 0.9, f'Average Clustering: {avg_clustering_coefficient:.3f}', \n",
    "             transform=plt.gca().transAxes,\n",
    "             fontsize=10, ha='right', va='center', bbox=dict(facecolor='white', alpha=0))\n",
    "    \n",
    "#for v, label in zip(pos_spring, node_labels):\n",
    "    #ax.text(v[0], v[1], label, color='black', fontsize=10, ha='center', va='center', fontweight='heavy', path_effects=[withStroke(linewidth=1, foreground='black')])\n",
    "    \n",
    "fig.set_size_inches(20, 20)\n",
    "\n",
    "file_dir = \"/Users/joebacchus/Desktop/PLOTS4LATEX/plots\" + 'plotsBIOTECH' + \".png\"\n",
    "plt.savefig(file_dir, dpi=300, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7abb34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
